{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Heuristics\n",
    "The approach tries to extract target-sentences that require some sort of action. Multi-Intents are not being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Increase max_length to handle larger texts\n",
    "nlp.max_length = 5_000_000  # Increase this to accommodate your text size\n",
    "\n",
    "\n",
    "# Initialize the tqdm progress bar for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/avocado_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text, message_id):\n",
    "    try:\n",
    "        # Process the text using spaCy\n",
    "        doc = nlp(text)\n",
    "        return [sent.text.strip() for sent in doc.sents]\n",
    "    except ValueError as e:\n",
    "        # Catch the error and log the message ID\n",
    "        if \"exceeds maximum of\" in str(e):\n",
    "            print(f\"Message ID {message_id}: Error processing text due to exceeding length.\")\n",
    "        else:\n",
    "            print(f\"Message ID {message_id}: Error - {str(e)}\")\n",
    "        return None  # Return None or some other marker to indicate failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 288642/503917 [2:43:14<1:47:59, 33.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID <19B3B310D020D311B57E00105A9A55246E0C67@COFFEE>: Error processing text due to exceeding length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 326311/503917 [3:03:23<1:54:48, 25.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID <200012150128.eBF1SkD09210@mailer.avocadoit.com>: Error processing text due to exceeding length.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503917/503917 [4:44:54<00:00, 29.48it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Apply the chunked sentence splitting function with message ID logging\n",
    "df['sentences'] = df.progress_apply(lambda row: split_sentences(row['extracted_text'], row['messageid']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_targets = df.explode('sentences').rename(columns={'sentences': 'sentence'}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../../data/processed/avocado_train_individual_sentences.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_exp_intent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
