{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../data/avocado_train.parquet',engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_object_pairs(text):\n",
    "    doc = nlp(text)\n",
    "    action_object_pairs = []  # List to hold (action, object) pairs\n",
    "    unconnected_dobjs = []    # List to hold unconnected dobj nouns\n",
    "    unconnected_verbs = []    # List to hold unconnected verbs\n",
    "    \n",
    "    for token in doc:\n",
    "        # Case 1: Check for action-object pairs\n",
    "        if token.pos_ == \"VERB\":\n",
    "            # Find its direct object (dobj) or object-related dependencies\n",
    "            objects = [child for child in token.children if child.dep_ in (\"dobj\", \"obj\", \"pobj\")]\n",
    "            for obj in objects:\n",
    "                action_object_pairs.append((token.text, obj.text))\n",
    "            \n",
    "            # Case 2: If the verb has no object-related children, it's unconnected\n",
    "            if not objects:\n",
    "                unconnected_verbs.append(token.text)\n",
    "        \n",
    "        # Case 3: Collect unconnected dobj nouns\n",
    "        if token.dep_ == \"dobj\" and token.pos_ == \"NOUN\":\n",
    "            # Check if this noun is connected to a verb by looking at its head\n",
    "            if token.head.pos_ != \"VERB\":\n",
    "                # If the head is not a verb, it's an unconnected dobj noun\n",
    "                unconnected_dobjs.append(token.text)\n",
    "    \n",
    "    return action_object_pairs, unconnected_dobjs, unconnected_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352123/352123 [1:46:41<00:00, 55.00it/s]  \n"
     ]
    }
   ],
   "source": [
    "df[\"action_object_pairs\"] = df[\"text\"].progress_apply(extract_action_object_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_action_object_pairs(value):\n",
    "    if isinstance(value, list):\n",
    "        # Flatten nested lists\n",
    "        return [item for sublist in value for item in sublist] if any(isinstance(i, list) for i in value) else value\n",
    "    elif pd.isna(value):\n",
    "        return []  # Replace NaN or None with an empty list\n",
    "    else:\n",
    "        return [value]  # Convert single non-list values to lists\n",
    "\n",
    "df['action_object_pairs'] = df['action_object_pairs'].apply(normalize_action_object_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547880    [([('watch', 'demo'), ('used', 'events'), ('up...\n",
       "507647    [([('adding', 'support'), ('using', 'crypto')]...\n",
       "390433    [([('contacted', 'me'), ('setting', 'meeting')...\n",
       "244808    [([('see', 'announcement'), ('editing', 'copy'...\n",
       "532146    [([('sign', 'form'), ('have', 'questions')], [...\n",
       "                                ...                        \n",
       "110268    [([('has', 'list'), ('has', 'Darshan'), ('iden...\n",
       "259178          [([('reach', 'me')], [], [Look, speaking])]\n",
       "365838    [([('download', 'file'), ('provide', 'interfac...\n",
       "131932    [([('do', 'what'), ('assist', 'you')], [], [le...\n",
       "121958                                  [([], [], [Added])]\n",
       "Name: action_object_pairs, Length: 352123, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['action_object_pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../../data/avocado_train_action_object_pairs.parquet',engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
